[
  {
    "objectID": "WGOA_source_data.html",
    "href": "WGOA_source_data.html",
    "title": "WGOA Source Data",
    "section": "",
    "text": "This folder has all the processed data for the WGOA in formats for rpath and formats for EwE software.\nPlease refer to the file names for the data source and the year of the data.\n\nr_files &lt;- list.files(path = \"~/WGOA-Ecopath-Rpath/WGOA_source_data\", pattern = \"\\\\.csv$\", full.names = FALSE, ignore.case=TRUE)\n\ncat(paste0(\"- \", r_files, collapse = \"\n\"))\n\n- B_target.csv\n- domain_sum.csv\n- F40_opt.csv\n- gak_zooplankton_B_time_series.csv\n- goa_bio_bystrat_2025_5_13.csv\n- goa_maturity_proportions.csv\n- goa_Zoop_TS_ECOFoci_data_v2.csv\n- species_weighted_temp_WGOA.csv\n- species_weighted_thermal_envelopes_WGOA.csv\n- WGOA_bioen.csv\n- wgoa_catch_ts_long_v2.csv\n- wgoa_catches_ft_cas_1990_mean.csv\n- wgoa_catches_ft_cas_final_mtkm2.csv\n- wgoa_ewe_pedigree.csv\n- wgoa_fed_catch_ts_wide_mt.csv\n- wgoa_fed_catch_ts_wide_mtkm2.csv\n- WGOA_full_time_series_v5.csv\n- wgoa_race_biomass_ts.csv\n- WGOA_ROMS_1000_ppL_detrended.csv\n- WGOA_ROMS_1000_ppS_detrended.csv\n- WGOA_ROMS_300_ppL_detrended.csv\n- WGOA_ROMS_300_ppS_detrended.csv\n- WGOA_ROMSpp_detrended.csv\n- wgoa_state_catch_ts_wide_mtkm2.csv\n\n\n\nROMS\n\nall files containing _ROMS_ are the detrended ROMS data, which is the model output from the WGOA ROMS model. the files are for 300 m and 1000 m depth, and contain the data for the entire WGOA region. ppS and ppL are primary production for small and large copepods.\nThe folder ROMSOutputWGOA contains all the ROMS outputs in long and wide formats, it also has files for production anommaly. The wide files contain the temperatures for each distinct ssps (126, 245 and 585).\n\nB_summary_ are the yearly biomass for ROMS NPZ model\nB_summary_month are the monthly biomass ROMS NPZ model\n\n\nAKFIN\n\nwgoa_state_catch_ts_wide_mtkm2.csv: this file has the fish ticket timeseries from AKFIN\nwgoa_catch files are also from AKFIN, they contain both fish ticket (mainly state) and CAS (federally managed) data. The file _1990_mean.csv is the mean between years 1990-1993, the baseline inputs for our Ecopath model. The files are also in wide and long formats.\nEwE_wgoa_.xlsx are the files queried by Jean Lee (AKFIN)\n\nRACE REEM\n\nwgoa_race_biomass_ts.csv: is the file derived from race REEM data.\nspecies_weighted_temp_WGOA.csv: This is from the guild calculations for the bioenergetics.\nspecies_weighted_thermal_envelopes_WGOA.csv: similar thing here.\ngoa_maturity_proportions.csv: Maturity proportions for the multistanza groups, resulting from the bottom trawl survey data. This information is used in the input of the multistanza groups in EwE software.\ndomain_sum.csv: is the biomass timeseries for the WGOA region\n\n\nNON-RACE TIME SERIES FILES\n\ngak_zooplankton_B_time_series.csv: GAK zooplankton biomass time series.\ngoa_Zoop_TS-ECOFoci_data_v2: ECOFoci data for zooplankton time series in the GOA region.\nSeabirds.xlsx: Seabird data for the GOA region.This has the information of all the colonies around GOA region.\nmammals_birds_salmon_biomass_timeseries.R: This file contains the biomass time series for mammals, birds and salmon in the GOA region.\nWGOA_full_time_series_v5.csv: Deprecated. This file needs to be updated, it is an older version.\n\nSIMULATION RUN FILES\nThese files were used for setting up the simulations to test some hypothesis. We will use them after the fitting.\n\nF40_opt.csv: this file presents the F40 values for target species, it was used in the excersise presented at ACLIM GOACLIM joint meeting.\nB_target: The Biomass target for the key species.\nWGOA_bioen.csv: this file contains the input parameters for the bioenergetics for the WGOA region."
  },
  {
    "objectID": "lookups.html",
    "href": "lookups.html",
    "title": "Lookups",
    "section": "",
    "text": "This directory contains lookup tables and scripts used to facilitate queries and data processing in the WGOA project. The lookups are essential for mapping species, gear types, and other categorical variables to their respective codes and names.\n\nRACE lookup\n\nlookup_table_code_WGOA_v1.R: This script generates the lookup tables for the WGOA project. It clean the species names and maps them to the functional groups used in the model. It uses the file “lookups/race_lookup_combined.csv” to generate the file “lookups/race_lookup_base_v2.csv” used in the race codes. The script will also clean the file “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30.csv” into the “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30_v2.csv” file to be used in the multistanza biomass timeseries estimation from the race_biomass_timeseries_var_sd_se_cv_general_code.R and race_biomass_timeseries_var_sd_se_cv.R scripts.\nAlaska_PreyLookup_MASTER.csv: This file contains the master lookup table for prey species in the Alaska ecosystem, including their functional groups and other relevant information. It is used to map species to their respective groups in the model.This file is used for guild and diet extraction from the bottom trawl survey.\ncombined_BTS_strata.csv: This file contains the combined bottom trawl survey strata information.\n\nAKFIN lookup\n\nmodel_species_for_ft_cas_akfin.csv: This file contains functional group names for WGOA model and the species names used in the AKFIN fish ticket and CAS data.\n\nMiscellaneous lookup\n\nGroup_Q_2021_WGOA.csv: This file contains the QQ for most of the funtional groups in the WGOA model.\npredlist_v2.csv: This file contains the predator list used in the WGOA and EGOA models, including their functional groups and other relevant information to be used in the multstanza Biomass timeseries extraction. We no longer use this, since it was replaced by “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30_v2.csv”"
  },
  {
    "objectID": "lookups.html#lookups-directory",
    "href": "lookups.html#lookups-directory",
    "title": "Lookups",
    "section": "",
    "text": "This directory contains lookup tables and scripts used to facilitate queries and data processing in the WGOA project. The lookups are essential for mapping species, gear types, and other categorical variables to their respective codes and names.\n\nRACE lookup\n\nlookup_table_code_WGOA_v1.R: This script generates the lookup tables for the WGOA project. It clean the species names and maps them to the functional groups used in the model. It uses the file “lookups/race_lookup_combined.csv” to generate the file “lookups/race_lookup_base_v2.csv” used in the race codes. The script will also clean the file “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30.csv” into the “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30_v2.csv” file to be used in the multistanza biomass timeseries estimation from the race_biomass_timeseries_var_sd_se_cv_general_code.R and race_biomass_timeseries_var_sd_se_cv.R scripts.\nAlaska_PreyLookup_MASTER.csv: This file contains the master lookup table for prey species in the Alaska ecosystem, including their functional groups and other relevant information. It is used to map species to their respective groups in the model.This file is used for guild and diet extraction from the bottom trawl survey.\ncombined_BTS_strata.csv: This file contains the combined bottom trawl survey strata information.\n\nAKFIN lookup\n\nmodel_species_for_ft_cas_akfin.csv: This file contains functional group names for WGOA model and the species names used in the AKFIN fish ticket and CAS data.\n\nMiscellaneous lookup\n\nGroup_Q_2021_WGOA.csv: This file contains the QQ for most of the funtional groups in the WGOA model.\npredlist_v2.csv: This file contains the predator list used in the WGOA and EGOA models, including their functional groups and other relevant information to be used in the multstanza Biomass timeseries extraction. We no longer use this, since it was replaced by “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30_v2.csv”"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This directory contains the raw input data used in the analyses. The data is organized into subdirectories based on the source and type of data.\n\n\n\nAKFIN: Folders associated with akfin query.\n\n2023: Contains AKFIN data (fish ticket and CAS) processed by the script akfin_wgoa_catch_2023.R. Refer to the script for details on how the data was processed.\nmetadata: tables to facilitate query and lookups.\n\nROMS: Contains the data from ROMS NEP 10k GOA\n\nNEP_10k_revised_indices folder: Contains the revised indices for the NEP 10k ROMS, averages and the sums. Please refer to the ROMS_output_WGOA_EGOA.R to see how the data is used.\n“NEP_variable_names.cvs”: Contains the variable names used in the GOA ROMS data.\n\nTime series before processing:\n\nbioenergetic_EBS_ACLIM2_bioen.cvs: bioenergetic information for EBS model\nGOA_BTS-size-Composition-by-Stratum.csv: GOA bottom trawl survey size composition by stratum\nmammals_bird_salmon_time_series_raw_v2.csv: time series of mammals, birds, and salmon\nnon_race_species.csv: all the species not sampled by the bottom trawl survey\nwgoa_catch_ts_raw_test.csv: akin catches\nWGOAfg_lookout.csv: deprecated lookoup table for WGOA fishery groups\n\nEwE models\n\nEGOA_20250514.eiixml: deprecated\nWGOA_9May2025.eiixml: deprecated"
  },
  {
    "objectID": "data.html#data-directory",
    "href": "data.html#data-directory",
    "title": "Data",
    "section": "",
    "text": "This directory contains the raw input data used in the analyses. The data is organized into subdirectories based on the source and type of data.\n\n\n\nAKFIN: Folders associated with akfin query.\n\n2023: Contains AKFIN data (fish ticket and CAS) processed by the script akfin_wgoa_catch_2023.R. Refer to the script for details on how the data was processed.\nmetadata: tables to facilitate query and lookups.\n\nROMS: Contains the data from ROMS NEP 10k GOA\n\nNEP_10k_revised_indices folder: Contains the revised indices for the NEP 10k ROMS, averages and the sums. Please refer to the ROMS_output_WGOA_EGOA.R to see how the data is used.\n“NEP_variable_names.cvs”: Contains the variable names used in the GOA ROMS data.\n\nTime series before processing:\n\nbioenergetic_EBS_ACLIM2_bioen.cvs: bioenergetic information for EBS model\nGOA_BTS-size-Composition-by-Stratum.csv: GOA bottom trawl survey size composition by stratum\nmammals_bird_salmon_time_series_raw_v2.csv: time series of mammals, birds, and salmon\nnon_race_species.csv: all the species not sampled by the bottom trawl survey\nwgoa_catch_ts_raw_test.csv: akin catches\nWGOAfg_lookout.csv: deprecated lookoup table for WGOA fishery groups\n\nEwE models\n\nEGOA_20250514.eiixml: deprecated\nWGOA_9May2025.eiixml: deprecated"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "WGOA-Ecopath-Rpath Model Documentation",
    "section": "",
    "text": "Here we have all the code associated with the data wrangling."
  },
  {
    "objectID": "code.html#code",
    "href": "code.html#code",
    "title": "WGOA-Ecopath-Rpath Model Documentation",
    "section": "",
    "text": "Here we have all the code associated with the data wrangling."
  },
  {
    "objectID": "code.html#folder-structure",
    "href": "code.html#folder-structure",
    "title": "WGOA-Ecopath-Rpath Model Documentation",
    "section": "Folder structure",
    "text": "Folder structure\nScripts are separated by their main function:\n\nr_files &lt;- list.files(path = \"~/WGOA-Ecopath-Rpath/code\", pattern = \"\\\\.r$\", full.names = FALSE, ignore.case=TRUE)\n\ncat(paste0(\"- \", r_files, collapse = \"\n\"))\n\n- akfin_to_EwE_format_v2.R\n- akfin_wgoa_catch_2023.R\n- bioenergetic_GOA_Q10_aveTemp_script.R\n- bioenergetic_pars2.r\n- bioenergetic_projections.r\n- Delta_correction.R\n- FourSystems_comp.R\n- FourSystems_functions.R\n- GAP_get_biomass_stratum.R\n- GAP_get_cpue.R\n- GAP_get_cpue_guild.R\n- ggraph_webplot_Rpath.R\n- GOA_rpath_setup.R\n- mammals_birds_salmon_biomass_timeseries.R\n- multistanza_maturity_proportions.R\n- pedigree_coversion_Rpath_EwE.R\n- race_biomass_timeseries_var_sd_se_cv.R\n- race_biomass_timeseries_var_sd_se_cv_general_code.R\n- REEM_download_functions.R\n- REEM_fooddata_functions.R\n- ROMS_data_transformation_anomaly.R\n- ROMS_output_WGOA_EGOA.R\n- rpath_graphs.R\n- rsim.plot.interactive.R\n- running_ecopath_network_plot.R\n- wgoa_Btarget.R\n- WGOA_EGOA_comp.R\n- WGOA_guilds_temp.R\n- xml_convert.r\n\n\n\nAKFIN:\n\nakfin_wgoa_catch_2023.R: This script retrieves and processes catch data from the AKFIN database for the WGOA region.\nakfin_to_EwE_format_v2.R: This script transforms the data retrieved from akfin_wgoa_catch_2023.R into a format suitable for Rpath.\n\nBIOENERGETICS:\n\nbioenergetic_GOA_Q10_aveRTemp_script.R: Script to update the group names of the “bioenergetic_EBS_ACLIM2_bioen.csv” file #to match WGOA names.\nbioenergetic_pars2.r: Bioenergetic params for GOACLIM. Uses the “WGOA_source_data/WGOA_bioen.csv” lookup file generated by the script above. It also uses the “WGOA_source_data/species_weighted_temp_WGOA.csv” file generated by the script WGOA_guilds_temp.\nbioenergetic_projections.r: This script will source the bioenergetic_pars2.r and apply the function bioen_params() that apply the consumption modifiers and respiration modifiers.\n\nWGOA_guilds_temp: This script was created to generate the temperature guild derived from the bottom trawl survey. It generates biomass-weighted average surface and bottom temperatures. This scripts relies on the files stored in google drive. The out files are: “WGOA_source_data/species_weighted_thermal_envelopes_WGOA.csv” and “WGOA_source_data/species_weighted_temp_WGOA.csv”\n\n\nROMS Climate Projections:\n\nDelta_correction.R: Script to update the group names of the bioenergetic_EBS_ACLIM2_bioen.csv file #to match WGOA names.\nROMS_output_WGOA_EGOA.R: Script for ROMS data collection # https://github.com/GOA-CLIM/ROMS_to_Index/blob/main/ROMS%20index%20generation%20example.qmd. This script sources the delta correction function, gathers the data for the different ssps, then will extract the Biomass and Production.\nFor biomass data transformation into EwE/Rpath input, filter data for depthclass “All” and NMFS_AREA 640,650 EGOA and 610-630 WGOA only.\nCarbon to wet weight conversions (B_ww_mg) can be found at:\nTable 1 (bottom explanation) from Pauly & Christensen 1995 for phytoplankton\n9: 1 ratio for the conversion of wet weight to carbon (Lockhart. A. & Cross. R. A. 1994. EMBO J. 13, 751-757)\nTable 2. from Kiorboe 2013 for the zooplankton\nLog(C mass)= a+blog(wet mass)\nC_to_ww &lt;- 10^((log10(value) - a) / b)\nUnits of Cop in the sum* files are mg C m^-2 of water column. Since the unit is already by area the conversion from mgm^-2 to mtkm^-2 will be *1e-3.\nThe script uses the files in ~/Data/NEP_10K_revised_indices/\nto produce the files in\n  out_folder &lt;- \"WGOA_source_data/ROMSOutputWGOA\"\n  out_folder2 &lt;- \"wgoa_data_rpath_fitting/\"\nFile names example: “/Long_”, region, “temp_monthly”, depth, “.csv”\nThe final formatted time-series files are saved in /wgoa_data_rpath_fitting/, and detailed monthly data is saved in /WGOA_source_data/ROMSOutputWGOA/.\nROMS_data_transformation_anomaly.R: is a retired code basis for the anomaly transformation that we see in ROMS_output_WGOA_EGOA.R\n\nRACE GAP data:\n\nrace_biomass_timeseries_var_sd_se_cv_general_code.R: This script was written to gather race data. At the moment the full race data sets are in the googledrive. The function REEM.loadclean.RACE.googledrive() found in the REEM_fooddata_fuctions.R script will load the data from the googledrive and clean it. Here we are using\n\nREEM.loadclean.strata.by.stratum(strata_lookup_file    = \"lookups/combined_BTS_strata.csv\",\n                             stratum_bin_column    = \"stratum\")\nto load the strata lookup file, which is used to filter the data by stratum.\nFor multistanza groups: One extra step is needed to calculate biomasses by juvenile and adult stages. We need the “lookups/Alaska_Multistanza_GOA_vonb_2025_04_30_v2.csv” file to do this. The script will use the read.clean.csv() function to load the VB file, which has all the information about cut-off length and growth rates for each species. The script will then use the read.clean.csv() function to load the strata lookup file, which is used to filter the data by stratum. The file has to be replaced to accomodate the different models.\nThe output file will be in the /wgoa_data_rpath_fitting/ folder, with the name “race_biomass_ts.csv” This file relies on the functions from the following scripts:\n\nREEM_download_functions.R: This script contains the functions used to download the data from the ORACLE database.\nREEM_fooddata_fuctions.R: This script contains the functions used to load and clean the data from the googledrive or can be modified to load data from a local folder. This code sources three other scripts with functions:\n\nGAP_get_cpue.R\nGAP_get_biomass_stratum.R\nGAP_get_cpue_guild.R\n\n\nRefer to the scripts to get familiarized with the functions.\nPEDIGREE:\n\npedigree_conversion_Rpath_EwE.R: This script will read the rpath pedigree file to create a EwE pedigree file.\n\nPLOTS\n\nggraph_webplot_Rpath.R: Network plot for object Rpath. This function is part of the rpathviz:: package developed by Bia Dias.\nrsim.plot.interactive.R: Plot for showing the relative biomass plot for Rsim objectm, using plotly::. This function is part of the rpathviz:: package.\nrpath_graphs.R: first version of the rsim.plot.interactive() funtion. Deprecated.\n\nEXPERIMENTAL CODE\n\nwgoa_Btarget.R: This code was developed by Andy W. to find B0. Please refer to the script for more details.\nxml_converter.r: This script is used to convert the xml files from the EwE model to a format that can be read by Rpath. It uses the xml2 package to read the xml files and convert them to a data frame."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to the documentation for the WGOA repository. This site describes the structure, data sources, and workflows used in this project."
  },
  {
    "objectID": "index.html#wgoa-repository",
    "href": "index.html#wgoa-repository",
    "title": "Home",
    "section": "",
    "text": "Welcome to the documentation for the WGOA repository. This site describes the structure, data sources, and workflows used in this project."
  },
  {
    "objectID": "index.html#sections",
    "href": "index.html#sections",
    "title": "Home",
    "section": "Sections",
    "text": "Sections\n\ncode: Scripts for data wrangling and manipulation.\ndata: Raw input data used in analyses.\nlookups: Tables and scripts for building lookup tables.\nWGOA_source_data: Original datasets from the WGOA survey.\nwgoa_data_rpath_fitting: Processed data ready for RPath model fitting."
  },
  {
    "objectID": "wgoa_data_rpath_fiting.html",
    "href": "wgoa_data_rpath_fiting.html",
    "title": "WGOA Data Rpath Fitting",
    "section": "",
    "text": "This folder has all the processed data for the WGOA in formats for rpath. These are the files used for fitting. It is important to note that we also have a similar folder for the EGOA model, since the files are processed in a batch. I will not replicate the explanations of the files for EGOA, since they are similar to the ones for WGOA.\n\nList of files in the WGOA Data Rpath Fitting folder\n\nr_files &lt;- list.files(path = \"~/WGOA-Ecopath-Rpath/wgoa_data_rpath_fitting/\", pattern = \"\\\\.csv$\", full.names = FALSE, ignore.case=TRUE)\n\ncat(paste0(\"- \", r_files, collapse = \"\n\"))\n\n- gak_zooplankton_b_ts_v2.csv\n- goaecofoci_zooplankton_b_ts_v2.csv\n- Long_WGOA_NPZ_B_annual_anomalies_1000_v2_corrected.csv\n- Long_WGOA_NPZ_B_monthly_anomalies_1000_v2_corrected.csv\n- Long_WGOA_NPZ_PP_monthly_anomalies_1000_v2_corrected.csv\n- Long_WGOA_temp_annual_1000.csv\n- Long_WGOA_temp_monthly_1000.csv\n- ssp126_wide_WGOA_temp_1000.csv\n- ssp245_wide_WGOA_temp_1000.csv\n- ssp585_wide_WGOA_temp_1000.csv\n- wgoa_catches_ft_cas_long.csv\n- wgoa_ewe_pedigree_cv.csv\n- wgoa_nonrace_biomass_ts_fitting_index.csv\n- wgoa_race_bio_totals.csv\n- wgoa_race_biomass_ts_fitting_index_v2_ka.csv\n- wgoa_race_biomass_ts_fitting_index_v2_tons_ka.csv\n- wgoa_race_juvadu_totals.csv\n- wgoa_rpath_pedigree.csv\n\n\n\nZooplankton from GAK and ECOFoci surveys\n\ngak_zooplankton_b_ts_v2.csv: GAK zooplankton biomass time series.\ngoaecofoci_zooplankton_b_ts_v2.csv: ECOFoci data for zooplankton time series in the GOA region.\n\nROMS data\n\nFor the ROMS data we are only using the 1000m depth contour. We calculated the anomalies, which are in the script ROMS_output_WGOA_EGOA.R, please refer to the code section for more explanation regarding the script.\n- `Long_WGOA_NPZ_B_annual_anomalies_1000_v2_corrected.csv`\n- `Long_WGOA_NPZ_B_monthly_anomalies_1000_v2_corrected.csv`\n- `Long_WGOA_NPZ_PP_monthly_anomalies_1000_v2_corrected.csv`\n- `Long_WGOA_temp_annual_1000.csv`\n- `Long_WGOA_temp_monthly_1000.csv`\n- `ssp126_wide_WGOA_temp_1000.csv`: Climate projections for the WGOA region under SSP126 scenario.\n- `ssp245_wide_WGOA_temp_1000.csv`: Climate projections for the WGOA region under SSP245 scenario.\n- `ssp585_wide_WGOA_temp_1000.csv`: Climate projections for the WGOA region under SSP585 scenario.\n\nAKFIN data\n\nwgoa_catches_ft_cas_long.csv: This file has the fish ticket timeseries from AKFIN, it is in long format.\n\nData Pedigree\n\nwgoa_ewe_pedigree_cv.csv: This file contains the data pedigree in EwE format.\nwgoa_rpath_pedigree.csv: This file contains the data pedigree in Rpath format, we transformed from EwE to Rpath format using the script pedigree_conversion_Rpath_EwE.R. Refer to the script for more details.\n\nBiomass time series\n\nwgoa_nonrace_biomass_ts_fitting_index.csv: All the species not surveyed by BTS.\nwgoa_race_biomass_ts_fitting_index_v2_ka.csv: BTS biomass time series in mt*km^-2\nwgoa_race_biomass_ts_fitting_index_v2_tons_ka.csv: BTS biomass time series in mt\nwgoa_race_bio_totals.csv: This file is the non-Rpath formated output. It won’t be read by Rpath, but I kept it for a sanity check.\nwgoa_race_juvadu_totals.csv: This file contains the juveniles and adult proportions and biomass time series. It won’t be read by Rpath, but I kept it for a sanity check."
  },
  {
    "objectID": "wgoa_data_rpath_fitting.html",
    "href": "wgoa_data_rpath_fitting.html",
    "title": "WGOA Data Rpath Fitting",
    "section": "",
    "text": "This folder has all the processed data for the WGOA in formats for rpath. These are the files used for fitting. It is important to note that we also have a similar folder for the EGOA model, since the files are processed in a batch. I will not replicate the explanations of the files for EGOA, since they are similar to the ones for WGOA.\n\nList of files in the WGOA Data Rpath Fitting folder\n\nr_files &lt;- list.files(path = \"~/WGOA-Ecopath-Rpath/wgoa_data_rpath_fitting/\", pattern = \"\\\\.csv$\", full.names = FALSE, ignore.case=TRUE)\n\ncat(paste0(\"- \", r_files, collapse = \"\n\"))\n\n- gak_zooplankton_b_ts_v2.csv\n- goaecofoci_zooplankton_b_ts_v2.csv\n- Long_WGOA_NPZ_B_annual_anomalies_1000_v2_corrected.csv\n- Long_WGOA_NPZ_B_monthly_anomalies_1000_v2_corrected.csv\n- Long_WGOA_NPZ_PP_monthly_anomalies_1000_v2_corrected.csv\n- Long_WGOA_temp_annual_1000.csv\n- Long_WGOA_temp_monthly_1000.csv\n- ssp126_wide_WGOA_temp_1000.csv\n- ssp245_wide_WGOA_temp_1000.csv\n- ssp585_wide_WGOA_temp_1000.csv\n- wgoa_catches_ft_cas_long.csv\n- wgoa_ewe_pedigree_cv.csv\n- wgoa_nonrace_biomass_ts_fitting_index.csv\n- wgoa_race_bio_totals.csv\n- wgoa_race_biomass_ts_fitting_index_v2_ka.csv\n- wgoa_race_biomass_ts_fitting_index_v2_tons_ka.csv\n- wgoa_race_juvadu_totals.csv\n- wgoa_rpath_pedigree.csv\n\n\n\nZooplankton from GAK and ECOFoci surveys\n\ngak_zooplankton_b_ts_v2.csv: GAK zooplankton biomass time series.\ngoaecofoci_zooplankton_b_ts_v2.csv: ECOFoci data for zooplankton time series in the GOA region.\n\nROMS data\n\nFor the ROMS data we are only using the 1000m depth contour. We calculated the anomalies, which are in the script ROMS_output_WGOA_EGOA.R, please refer to the code section for more explanation regarding the script.\n- `Long_WGOA_NPZ_B_annual_anomalies_1000_v2_corrected.csv`\n- `Long_WGOA_NPZ_B_monthly_anomalies_1000_v2_corrected.csv`\n- `Long_WGOA_NPZ_PP_monthly_anomalies_1000_v2_corrected.csv`\n- `Long_WGOA_temp_annual_1000.csv`\n- `Long_WGOA_temp_monthly_1000.csv`\n- `ssp126_wide_WGOA_temp_1000.csv`: Climate projections for the WGOA region under SSP126 scenario.\n- `ssp245_wide_WGOA_temp_1000.csv`: Climate projections for the WGOA region under SSP245 scenario.\n- `ssp585_wide_WGOA_temp_1000.csv`: Climate projections for the WGOA region under SSP585 scenario.\n\nAKFIN data\n\nwgoa_catches_ft_cas_long.csv: This file has the fish ticket timeseries from AKFIN, it is in long format.\n\nData Pedigree\n\nwgoa_ewe_pedigree_cv.csv: This file contains the data pedigree in EwE format.\nwgoa_rpath_pedigree.csv: This file contains the data pedigree in Rpath format, we transformed from EwE to Rpath format using the script pedigree_conversion_Rpath_EwE.R. Refer to the script for more details.\n\nBiomass time series\n\nwgoa_nonrace_biomass_ts_fitting_index.csv: All the species not surveyed by BTS.\nwgoa_race_biomass_ts_fitting_index_v2_ka.csv: BTS biomass time series in mt*km^-2\nwgoa_race_biomass_ts_fitting_index_v2_tons_ka.csv: BTS biomass time series in mt\nwgoa_race_bio_totals.csv: This file is the non-Rpath formated output. It won’t be read by Rpath, but I kept it for a sanity check.\nwgoa_race_juvadu_totals.csv: This file contains the juveniles and adult proportions and biomass time series. It won’t be read by Rpath, but I kept it for a sanity check."
  }
]